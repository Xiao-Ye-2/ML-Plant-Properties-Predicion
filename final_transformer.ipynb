{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YZM\\Desktop\\for fun\\pytorch\\torch-playground\\lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\YZM\\Desktop\\for fun\\pytorch\\torch-playground\\lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting image features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100%|██████████| 39277/39277 [15:48<00:00, 41.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image feature extraction completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import ViTModel, ViTFeatureExtractor, DeiTFeatureExtractor, DeiTModel, AutoFeatureExtractor, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from torchvision import models, transforms\n",
    "\n",
    "# Load data\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "data = pd.read_csv('./data/train_preprocessed_qt+2.csv')\n",
    "\n",
    "# Define columns\n",
    "traits_columns = data.columns[-6:]\n",
    "features_columns = data.columns.difference(traits_columns)\n",
    "\n",
    "# Construct image paths\n",
    "data['image_path'] = data['id'].apply(lambda x: os.path.join('./data/train_images', f\"{x}.jpeg\"))\n",
    "\n",
    "# feature_extractor = AutoFeatureExtractor.from_pretrained('microsoft/swin-base-patch4-window7-224')\n",
    "# model = AutoModel.from_pretrained('microsoft/swin-base-patch4-window7-224').to(device)  # not as good as VIT\n",
    "\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
    "model = ViTModel.from_pretrained('google/vit-base-patch16-224').to(device)\n",
    "\n",
    "# feature_extractor = DeiTFeatureExtractor.from_pretrained('facebook/deit-base-distilled-patch16-224')\n",
    "# model = DeiTModel.from_pretrained('facebook/deit-base-distilled-patch16-224').to(device)  # not as good as VIT\n",
    "\n",
    "# feature_extractor = AutoFeatureExtractor.from_pretrained('facebook/dino-vitb16')\n",
    "# model = AutoModel.from_pretrained('facebook/dino-vitb16').to(device)  # not as good as VIT\n",
    "\n",
    "# model = models.resnet50(weights='DEFAULT').to(device)\n",
    "# model.eval()  # Set the model to evaluation mode\n",
    "# feature_extractor = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),  # Resize images to 224x224 pixels\n",
    "#     transforms.ToTensor(),  # Convert image to PyTorch tensor\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize based on ImageNet stats\n",
    "# ])\n",
    "# def extract_features(image_path):\n",
    "#     image = Image.open(image_path).convert('RGB')\n",
    "#     inputs = feature_extractor(image).unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(inputs)\n",
    "#     return outputs.squeeze().cpu().numpy()\n",
    "\n",
    "# Function to extract image features\n",
    "def extract_features(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    inputs = feature_extractor(images=image, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()\n",
    "\n",
    "print(\"Encoding image features...\")\n",
    "\n",
    "# Extract features for each image\n",
    "data['image_encodes'] = [extract_features(img) for img in tqdm(data['image_path'], desc=\"Encoding Features\")]\n",
    "\n",
    "print(\"Image feature encoding completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "image_features_array = np.vstack(data['image_encodes'].values)\n",
    "\n",
    "image_features_df = pd.DataFrame(image_features_array, index=data.index)\n",
    "\n",
    "data = pd.concat([data, image_features_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['id', 'image_path', 'image_encodes'])\n",
    "data.columns = data.columns.astype(str)\n",
    "\n",
    "X = data.drop(columns=traits_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.1\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          16\n",
      "Memory Avail:       9.26 GB / 31.77 GB (29.1%)\n",
      "Disk Space Avail:   11.31 GB / 300.00 GB (3.8%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 7200s\n",
      "AutoGluon will save models to \"./vit-model-qt+2-5\"\n",
      "Train Data Rows:    35349\n",
      "Train Data Columns: 931\n",
      "Tuning Data Rows:    3928\n",
      "Tuning Data Columns: 931\n",
      "Label Column:       X3112_mean\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9371.95 MB\n",
      "\tTrain Data (Original)  Memory Usage: 163.91 MB (1.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 931 | ['WORLDCLIM_BIO1_annual_mean_temperature', 'WORLDCLIM_BIO12_annual_precipitation', 'WORLDCLIM_BIO13.BIO14_delta_precipitation_of_wettest_and_dryest_month', 'WORLDCLIM_BIO15_precipitation_seasonality', 'WORLDCLIM_BIO4_temperature_seasonality', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 931 | ['WORLDCLIM_BIO1_annual_mean_temperature', 'WORLDCLIM_BIO12_annual_precipitation', 'WORLDCLIM_BIO13.BIO14_delta_precipitation_of_wettest_and_dryest_month', 'WORLDCLIM_BIO15_precipitation_seasonality', 'WORLDCLIM_BIO4_temperature_seasonality', ...]\n",
      "\t2.7s = Fit runtime\n",
      "\t931 features in original data used to generate 931 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 163.91 MB (1.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 3.0s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 7197.0s of the 7197.0s of remaining time.\n",
      "\t0.3339\t = Validation score   (r2)\n",
      "\t1.22s\t = Training   runtime\n",
      "\t1.15s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 7194.49s of the 7194.48s of remaining time.\n",
      "\t0.3383\t = Validation score   (r2)\n",
      "\t1.21s\t = Training   runtime\n",
      "\t1.04s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 7192.11s of the 7192.1s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.0198599\tvalid_set's r2: 0.366548\n",
      "[2000]\tvalid_set's l2: 0.0196857\tvalid_set's r2: 0.372103\n",
      "[3000]\tvalid_set's l2: 0.0195937\tvalid_set's r2: 0.375041\n",
      "[4000]\tvalid_set's l2: 0.0195312\tvalid_set's r2: 0.377033\n",
      "[5000]\tvalid_set's l2: 0.0195118\tvalid_set's r2: 0.377652\n",
      "[6000]\tvalid_set's l2: 0.0195004\tvalid_set's r2: 0.378014\n",
      "[7000]\tvalid_set's l2: 0.0195029\tvalid_set's r2: 0.377936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.3782\t = Validation score   (r2)\n",
      "\t178.26s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 7013.4s of the 7013.4s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.0197672\tvalid_set's r2: 0.369504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.37\t = Validation score   (r2)\n",
      "\t47.26s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 6966.03s of the 6966.02s of remaining time.\n",
      "\t0.3267\t = Validation score   (r2)\n",
      "\t1909.61s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 5055.84s of the 5055.83s of remaining time.\n",
      "\t0.3793\t = Validation score   (r2)\n",
      "\t783.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 4272.74s of the 4272.74s of remaining time.\n",
      "\t0.3299\t = Validation score   (r2)\n",
      "\t400.72s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 3871.44s of the 3871.44s of remaining time.\n",
      "No improvement since epoch 4: early stopping\n",
      "\t0.3409\t = Validation score   (r2)\n",
      "\t49.46s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 3821.77s of the 3821.76s of remaining time.\n",
      "\t0.3491\t = Validation score   (r2)\n",
      "\t42.72s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 3778.86s of the 3778.85s of remaining time.\n",
      "\t0.3539\t = Validation score   (r2)\n",
      "\t51.38s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 3727.34s of the 3727.33s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.0195251\tvalid_set's r2: 0.377226\n",
      "[2000]\tvalid_set's l2: 0.0194795\tvalid_set's r2: 0.378681\n",
      "[3000]\tvalid_set's l2: 0.0194731\tvalid_set's r2: 0.378885\n",
      "[4000]\tvalid_set's l2: 0.0194705\tvalid_set's r2: 0.37897\n",
      "[5000]\tvalid_set's l2: 0.0194701\tvalid_set's r2: 0.378983\n",
      "[6000]\tvalid_set's l2: 0.0194699\tvalid_set's r2: 0.378989\n",
      "[7000]\tvalid_set's l2: 0.0194698\tvalid_set's r2: 0.378991\n",
      "[8000]\tvalid_set's l2: 0.0194698\tvalid_set's r2: 0.378991\n",
      "[9000]\tvalid_set's l2: 0.0194698\tvalid_set's r2: 0.378991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.379\t = Validation score   (r2)\n",
      "\t835.27s\t = Training   runtime\n",
      "\t0.76s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 719.7s of the 2890.31s of remaining time.\n",
      "\tEnsemble Weights: {'KNeighborsDist': 0.304, 'CatBoost': 0.174, 'NeuralNetFastAI': 0.174, 'NeuralNetTorch': 0.13, 'LightGBMLarge': 0.13, 'LightGBMXT': 0.087}\n",
      "\t0.4177\t = Validation score   (r2)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4309.96s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1727.8 rows/s (3928 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./vit-model-qt+2-5\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r2': 0.4177366071672023, 'root_mean_squared_error': -0.1351112483705678, 'mean_squared_error': -0.018255049436253255, 'mean_absolute_error': -0.08730440231539532, 'pearsonr': 0.6466097318357973, 'median_absolute_error': -0.05204206057729309}\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "# Define the target feature and split the data\n",
    "target_feature = 5\n",
    "target_column = traits_columns[target_feature]\n",
    "y = data[target_column]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "val_df = pd.concat([X_val, y_val], axis=1)\n",
    "\n",
    "# Initialize the TabularPredictor\n",
    "predictor = TabularPredictor(\n",
    "    label=target_column,\n",
    "    problem_type='regression',\n",
    "    eval_metric='r2',\n",
    "    path=f'./vit-model-qt+2-{target_feature}'  # Path to save the model\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "predictor.fit(\n",
    "    train_data=train_df,\n",
    "    tuning_data=val_df,\n",
    "    time_limit=7200  # Time limit for training\n",
    ")\n",
    "\n",
    "# Evaluate model performance\n",
    "performance = predictor.evaluate(val_df)\n",
    "print(performance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs480",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
