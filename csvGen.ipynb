{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39277\n",
      "Min values: [6.30849029e-01 1.33873997e+02 1.96990260e+04 3.45940007e+03\n",
      " 1.36050911e+01 3.97556994e+05]\n",
      "Max values: [1.37534090e+00 1.68974129e+02 1.97145678e+04 3.68232452e+03\n",
      " 1.68894152e+01 4.05884021e+05]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "data_frame = pd.read_csv(\"data/train_preprocessed_outlier_tnoNorm.csv\")\n",
    "target_columns = data_frame.columns[164:]\n",
    "\n",
    "# print rows counth of dataframe\n",
    "print(len(data_frame))\n",
    "infer_min = data_frame[target_columns].min()\n",
    "infer_max = data_frame[target_columns].max()\n",
    "print(f\"Min values: {infer_min.values}\")\n",
    "print(f\"Max values: {infer_max.values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the models, loss function, and optimizers\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YZM\\Desktop\\for fun\\pytorch\\torch-playground\\lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\YZM\\Desktop\\for fun\\pytorch\\torch-playground\\lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting image features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100%|██████████| 6391/6391 [02:26<00:00, 43.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image feature extraction completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from transformers import ViTModel, ViTFeatureExtractor\n",
    "from tqdm import tqdm\n",
    "\n",
    "data = pd.read_csv('./data/test_preprocessed_qt+2.csv')\n",
    "\n",
    "# Construct image paths\n",
    "data['image_path'] = data['id'].apply(lambda x: os.path.join('./data/test_images', f\"{x}.jpeg\"))\n",
    "\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
    "model = ViTModel.from_pretrained('google/vit-base-patch16-224').to(device)\n",
    "\n",
    "# Function to extract image features\n",
    "def extract_features(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    inputs = feature_extractor(images=image, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()\n",
    "\n",
    "print(\"Extracting image features...\")\n",
    "\n",
    "# Extract features for each image\n",
    "data['image_encodes'] = [extract_features(img) for img in tqdm(data['image_path'], desc=\"Extracting Features\")]\n",
    "\n",
    "print(\"Image feature extraction completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features_array = np.vstack(data['image_encodes'].values)\n",
    "\n",
    "image_features_df = pd.DataFrame(image_features_array, index=data.index)\n",
    "\n",
    "data = pd.concat([data, image_features_df], axis=1)\n",
    "\n",
    "data = data.drop(columns=['id', 'image_path', 'image_encodes'])\n",
    "data.columns = data.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "predictor1 = TabularPredictor.load('vit-model-qt+2-0')\n",
    "predictor2 = TabularPredictor.load('vit-model-qt+2-1')\n",
    "predictor3 = TabularPredictor.load('vit-model-qt+2-2')\n",
    "predictor4 = TabularPredictor.load('vit-model-qt+2-3')\n",
    "predictor5 = TabularPredictor.load('vit-model-qt+2-4')\n",
    "predictor6 = TabularPredictor.load('vit-model-qt+2-5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_max = torch.tensor(infer_max.to_numpy()).to(device)\n",
    "infer_min = torch.tensor(infer_min.to_numpy()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6391, 6])\n"
     ]
    }
   ],
   "source": [
    "feature1 = predictor1.predict(data)\n",
    "feature2 = predictor2.predict(data)\n",
    "feature3 = predictor3.predict(data)\n",
    "feature4 = predictor4.predict(data)\n",
    "feature5 = predictor5.predict(data)\n",
    "feature6 = predictor6.predict(data)\n",
    "\n",
    "predictions = torch.tensor([feature1, feature2, feature3, feature4, feature5, feature6]).to(device)\n",
    "predictions = torch.transpose(predictions, 0, 1).to(device)\n",
    "print(predictions.shape)\n",
    "\n",
    "predictions = predictions * (infer_max - infer_min) + infer_min\n",
    "\n",
    "# Load the test data to get the 'id' column\n",
    "data_id = pd.read_csv('./data/test.csv')\n",
    "\n",
    "# Prepare the submission DataFrame with new predictions\n",
    "submission = pd.DataFrame(predictions, columns=['X4', 'X11', 'X18', 'X26', 'X50', 'X3112'])\n",
    "submission['id'] = data_id['id']\n",
    "submission = submission[['id', 'X4', 'X11', 'X18', 'X26', 'X50', 'X3112']]\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "submission.to_csv('j228ye_vit-predict.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
