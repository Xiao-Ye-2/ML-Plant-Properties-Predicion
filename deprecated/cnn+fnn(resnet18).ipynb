{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchmetrics import R2Score\n",
    "from PIL import Image\n",
    "\n",
    "# Define custom dataset\n",
    "class PlantDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = str(self.data_frame.iloc[idx, 0])\n",
    "        img_path = os.path.join(self.root_dir, img_id + '.jpeg')\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        ancillary_data = self.data_frame.iloc[idx, 1:164].values.astype('float32')\n",
    "        if 'train' in self.root_dir:\n",
    "            labels = self.data_frame.iloc[idx, 164:].values.astype('float32')\n",
    "            return [ancillary_data, image], labels\n",
    "        else:\n",
    "            return [ancillary_data, image], img_id\n",
    "\n",
    "# Define transformations\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    # No noise needed since clear images\n",
    "])\n",
    "\n",
    "# Load the datasets\n",
    "train_dataset = PlantDataset(csv_file='data/train_preprocessed.csv', root_dir='data/train_images', transform=data_transforms)\n",
    "test_dataset = PlantDataset(csv_file='data/test_preprocessed.csv', root_dir='data/test_images', transform=data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training subset and validation subset\n",
    "# train_size = len(train_dataset) // 5\n",
    "# train_subset_indices, _ = train_test_split(list(range(len(train_dataset))), train_size=train_size, random_state=42)\n",
    "# val_size = int(0.15 * train_size)\n",
    "# train_indices, val_indices = train_test_split(train_subset_indices, test_size=val_size, random_state=42)\n",
    "\n",
    "# train_loader = DataLoader(Subset(train_dataset, train_indices), batch_size=32, shuffle=True, pin_memory=True)\n",
    "# val_loader = DataLoader(Subset(train_dataset, val_indices), batch_size=32, shuffle=False, pin_memory=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, pin_memory=True)\n",
    "\n",
    "\n",
    "val_fraction = 1 / 15  # Change to 1/20 if desired\n",
    "val_size = int(val_fraction * len(train_dataset))\n",
    "\n",
    "# Split the dataset indices into training and validation\n",
    "train_indices, val_indices = train_test_split(\n",
    "    list(range(len(train_dataset))), test_size=val_size, random_state=42)\n",
    "\n",
    "# Create DataLoaders for training, validation, and test sets\n",
    "train_loader = DataLoader(Subset(train_dataset, train_indices), batch_size=32, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(Subset(train_dataset, val_indices), batch_size=32, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6391\n",
      "200\n",
      "1265\n",
      "91\n"
     ]
    }
   ],
   "source": [
    "print(len(test_dataset))\n",
    "print(len(test_loader))\n",
    "print(len(train_loader))\n",
    "print(len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18_essay(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18_essay, self).__init__()\n",
    "        self.base_cnn = models.resnet18(weights='DEFAULT')\n",
    "        self.base_cnn.fc = nn.Identity()\n",
    "\n",
    "        self.cnn_output = nn.Sequential(\n",
    "            nn.Linear(512, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 4)\n",
    "        )\n",
    "\n",
    "        self.output_dense = nn.Sequential(\n",
    "            nn.Linear(163, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 4)\n",
    "        )\n",
    "\n",
    "        self.main_output = nn.Sequential(\n",
    "            nn.Linear(8, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        ancillary_data, images = x\n",
    "        output_cnn = self.cnn_output(self.base_cnn(images))\n",
    "        output_dense = self.output_dense(ancillary_data)\n",
    "\n",
    "        combined = torch.cat((output_cnn, output_dense), dim=1)\n",
    "        return self.main_output(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the models, loss function, and optimizers\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "val_r2_scores = []\n",
    "\n",
    "model = ResNet18_essay().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "r2_score = R2Score(num_outputs=1).to(device)\n",
    "\n",
    "num_epochs = 30\n",
    "target_feature = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Training Loss: 0.02616556, Validation Loss: 0.02617103, R² Score: 0.09694344\n",
      "Epoch [2/30], Training Loss: 0.02318273, Validation Loss: 0.02591527, R² Score: 0.10572278\n",
      "Epoch [3/30], Training Loss: 0.01909510, Validation Loss: 0.02713733, R² Score: 0.06450385\n",
      "Epoch [4/30], Training Loss: 0.01233398, Validation Loss: 0.03011707, R² Score: -0.03977156\n",
      "Epoch [5/30], Training Loss: 0.00764129, Validation Loss: 0.03091599, R² Score: -0.06386256\n",
      "Epoch [6/30], Training Loss: 0.00521110, Validation Loss: 0.03153996, R² Score: -0.08535898\n",
      "Epoch [7/30], Training Loss: 0.00431538, Validation Loss: 0.02987748, R² Score: -0.02978194\n",
      "Epoch [8/30], Training Loss: 0.00383953, Validation Loss: 0.03016535, R² Score: -0.03755820\n",
      "Epoch [9/30], Training Loss: 0.00354024, Validation Loss: 0.02976078, R² Score: -0.02414119\n",
      "Epoch [10/30], Training Loss: 0.00334068, Validation Loss: 0.02922190, R² Score: -0.00483119\n",
      "Epoch [11/30], Training Loss: 0.00290236, Validation Loss: 0.02944074, R² Score: -0.01146841\n",
      "Epoch [12/30], Training Loss: 0.00264093, Validation Loss: 0.02876447, R² Score: 0.00963926\n",
      "Epoch [13/30], Training Loss: 0.00249550, Validation Loss: 0.02910034, R² Score: -0.00120211\n",
      "Epoch [14/30], Training Loss: 0.00233968, Validation Loss: 0.02893325, R² Score: 0.00455827\n",
      "Epoch [15/30], Training Loss: 0.00209322, Validation Loss: 0.02854477, R² Score: 0.01908720\n",
      "Epoch [16/30], Training Loss: 0.00196688, Validation Loss: 0.02895449, R² Score: 0.00313866\n",
      "Epoch [17/30], Training Loss: 0.00185811, Validation Loss: 0.02831595, R² Score: 0.02393454\n",
      "Epoch [18/30], Training Loss: 0.00172102, Validation Loss: 0.02848417, R² Score: 0.01962936\n",
      "Epoch [19/30], Training Loss: 0.00159930, Validation Loss: 0.02833332, R² Score: 0.02400982\n",
      "Epoch [20/30], Training Loss: 0.00147071, Validation Loss: 0.02801280, R² Score: 0.03448653\n",
      "Epoch [21/30], Training Loss: 0.00138861, Validation Loss: 0.02801860, R² Score: 0.03539991\n",
      "Epoch [22/30], Training Loss: 0.00127059, Validation Loss: 0.02844266, R² Score: 0.02015573\n",
      "Epoch [23/30], Training Loss: 0.00121227, Validation Loss: 0.02859655, R² Score: 0.01466173\n",
      "Epoch [24/30], Training Loss: 0.00112308, Validation Loss: 0.02875831, R² Score: 0.00855929\n",
      "Epoch [25/30], Training Loss: 0.00107732, Validation Loss: 0.02843210, R² Score: 0.01989204\n",
      "Epoch [26/30], Training Loss: 0.00099730, Validation Loss: 0.02852165, R² Score: 0.01831818\n",
      "Epoch [27/30], Training Loss: 0.00094648, Validation Loss: 0.02826363, R² Score: 0.02583295\n",
      "Epoch [28/30], Training Loss: 0.00089524, Validation Loss: 0.02846159, R² Score: 0.01853877\n",
      "Epoch [29/30], Training Loss: 0.00082562, Validation Loss: 0.02867491, R² Score: 0.01118356\n",
      "Epoch [30/30], Training Loss: 0.00078801, Validation Loss: 0.02883541, R² Score: 0.00534534\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for [ancillary_data, images], labels in train_loader:\n",
    "        ancillary_data, images, labels = ancillary_data.to(device), images.to(device), labels.to(device)\n",
    "        labels = labels[:,target_feature].unsqueeze(1)\n",
    "\n",
    "        outputs = model([ancillary_data, images])\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate training loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Record average training loss for this epoch\n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_outputs = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for [ancillary_data, images], labels in val_loader:\n",
    "            ancillary_data, images, labels = ancillary_data.to(device), images.to(device), labels.to(device)\n",
    "            labels = labels[:,target_feature].unsqueeze(1)\n",
    "\n",
    "            outputs = model([ancillary_data, images])\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            val_outputs.append(outputs)\n",
    "            val_labels.append(labels)\n",
    "\n",
    "    # Record average validation loss for this epoch\n",
    "    val_loss /= len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    # Calculate R² score\n",
    "    val_outputs = torch.cat(val_outputs)\n",
    "    val_labels = torch.cat(val_labels)\n",
    "    r2 = r2_score(val_outputs, val_labels).item()\n",
    "    val_r2_scores.append(r2)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.8f}, Validation Loss: {val_loss:.8f}, R² Score: {r2:.8f}')\n",
    "    if epoch + 1 >= 5:\n",
    "        torch.save(model.state_dict(), f'temp/{target_feature + 1}_epoch_{epoch+1}_resnet18.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.MSELoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# r2_score = R2Score(num_outputs=1).to(device)\n",
    "\n",
    "# num_epochs = 10\n",
    "# target_feature = 0\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     train_loss = 0\n",
    "#     for [ancillary_data, images], labels in train_loader:\n",
    "#         ancillary_data, images, labels = ancillary_data.to(device), images.to(device), labels.to(device)\n",
    "#         labels = labels[:,target_feature].unsqueeze(1)\n",
    "\n",
    "#         outputs = model([ancillary_data, images])\n",
    "#         loss = criterion(outputs, labels)\n",
    "\n",
    "#         # Backward pass and optimization\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # Accumulate training loss\n",
    "#         train_loss += loss.item()\n",
    "\n",
    "#     # Record average training loss for this epoch\n",
    "#     train_loss /= len(train_loader)\n",
    "#     train_losses.append(train_loss)\n",
    "\n",
    "#     # Validation loop\n",
    "#     model.eval()\n",
    "#     val_loss = 0\n",
    "#     val_outputs = []\n",
    "#     val_labels = []\n",
    "#     with torch.no_grad():\n",
    "#         for [ancillary_data, images], labels in val_loader:\n",
    "#             ancillary_data, images, labels = ancillary_data.to(device), images.to(device), labels.to(device)\n",
    "#             labels = labels[:,target_feature].unsqueeze(1)\n",
    "\n",
    "#             outputs = model([ancillary_data, images])\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             val_loss += loss.item()\n",
    "\n",
    "#             val_outputs.append(outputs)\n",
    "#             val_labels.append(labels)\n",
    "\n",
    "#     # Record average validation loss for this epoch\n",
    "#     val_loss /= len(val_loader)\n",
    "#     val_losses.append(val_loss)\n",
    "\n",
    "#     # Calculate R² score\n",
    "#     val_outputs = torch.cat(val_outputs)\n",
    "#     val_labels = torch.cat(val_labels)\n",
    "#     r2 = r2_score(val_outputs, val_labels).item()\n",
    "#     val_r2_scores.append(r2)\n",
    "\n",
    "#     print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.8f}, Validation Loss: {val_loss:.8f}, R² Score: {r2:.8f}')\n",
    "#     if epoch + 1 >= 5:\n",
    "#         torch.save(model.state_dict(), f'temp/{target_feature + 1}_epoch_{epoch+1}_resnet18.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
