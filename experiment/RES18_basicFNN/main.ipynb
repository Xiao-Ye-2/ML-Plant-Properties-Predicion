{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "# Define custom dataset\n",
    "class PlantDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = str(self.data_frame.iloc[idx, 0])\n",
    "        img_path = os.path.join(self.root_dir, img_id + '.jpeg')\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        ancillary_data = self.data_frame.iloc[idx, 1:164].values.astype('float32')\n",
    "        if 'train' in self.root_dir:\n",
    "            labels = self.data_frame.iloc[idx, 164:].values.astype('float32')\n",
    "            return [ancillary_data, image], labels\n",
    "        else:\n",
    "            return [ancillary_data, image]\n",
    "\n",
    "# Define transformations\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    # No noise needed since clear images\n",
    "])\n",
    "\n",
    "# Load the datasets\n",
    "train_dataset = PlantDataset(csv_file='data/train.csv', root_dir='data/train_images', transform=data_transforms)\n",
    "test_dataset = PlantDataset(csv_file='data/test.csv', root_dir='data/test_images', transform=data_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43363\n",
      "6391\n",
      "1356\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "print(len(train_loader))\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom dataset for images\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None, train=True):\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = str(self.data_frame.iloc[idx, 0])\n",
    "        img_path = os.path.join(self.root_dir, img_id + '.jpeg')\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.train:\n",
    "            labels = self.data_frame.iloc[idx, 164:].values.astype('float32')\n",
    "            return image, labels\n",
    "        else:\n",
    "            return image, img_id\n",
    "\n",
    "# Define custom dataset for ancillary data\n",
    "class AncillaryDataset(Dataset):\n",
    "    def __init__(self, csv_file, train=True):\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ancillary_data = self.data_frame.iloc[idx, 1:164].values.astype('float32')\n",
    "        if self.train:\n",
    "            labels = self.data_frame.iloc[idx, 164:].values.astype('float32')\n",
    "            return ancillary_data, labels\n",
    "        else:\n",
    "            img_id = self.data_frame.iloc[idx, 0]\n",
    "            return ancillary_data, img_id\n",
    "\n",
    "# Define transformations for images\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load the datasets\n",
    "train_image_dataset = ImageDataset(csv_file='data/train.csv', root_dir='data/train_images', transform=data_transforms, train=True)\n",
    "test_image_dataset = ImageDataset(csv_file='data/test.csv', root_dir='data/test_images', transform=data_transforms, train=False)\n",
    "\n",
    "train_ancillary_dataset = AncillaryDataset(csv_file='data/train.csv', train=True)\n",
    "test_ancillary_dataset = AncillaryDataset(csv_file='data/test.csv', train=False)\n",
    "\n",
    "train_image_loader = DataLoader(train_image_dataset, batch_size=32, shuffle=True)\n",
    "test_image_loader = DataLoader(test_image_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "train_ancillary_loader = DataLoader(train_ancillary_dataset, batch_size=32, shuffle=True)\n",
    "test_ancillary_loader = DataLoader(test_ancillary_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model for images\n",
    "class ImageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageModel, self).__init__()\n",
    "        self.cnn = models.resnet18(pretrained=True)\n",
    "        self.cnn.fc = nn.Sequential(\n",
    "            nn.Linear(self.cnn.fc.in_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 6)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)\n",
    "\n",
    "# Define the fully connected model for ancillary data\n",
    "class AncillaryModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AncillaryModel, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(163, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 6)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YZM\\Desktop\\for fun\\pytorch\\torch-playground\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\YZM\\Desktop\\for fun\\pytorch\\torch-playground\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the models, loss function, and optimizers\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "image_model = ImageModel().to(device)\n",
    "ancillary_model = AncillaryModel().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "image_optimizer = optim.Adam(image_model.parameters(), lr=0.001)\n",
    "ancillary_optimizer = optim.Adam(ancillary_model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Image Model Loss: 118905.7461\n",
      "Epoch 2/10, Image Model Loss: 110258.1904\n",
      "Epoch 3/10, Image Model Loss: 104731.3162\n",
      "Epoch 4/10, Image Model Loss: 99524.5344\n",
      "Epoch 5/10, Image Model Loss: 97730.0542\n",
      "Epoch 6/10, Image Model Loss: 90986.5182\n",
      "Epoch 7/10, Image Model Loss: 81622.0190\n",
      "Epoch 8/10, Image Model Loss: 83884.8307\n",
      "Epoch 9/10, Image Model Loss: 92388.3497\n",
      "Epoch 10/10, Image Model Loss: 74668.8965\n"
     ]
    }
   ],
   "source": [
    "# Training loop for image model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    image_model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_image_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        image_optimizer.zero_grad()\n",
    "        outputs = image_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        image_optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss = running_loss / len(train_image_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Image Model Loss: {train_loss:.4f}')\n",
    "\n",
    "# # Training loop for ancillary model\n",
    "# for epoch in range(num_epochs):\n",
    "#     ancillary_model.train()\n",
    "#     running_loss = 0.0\n",
    "#     for ancillary_data, labels in train_ancillary_loader:\n",
    "#         ancillary_data, labels = ancillary_data.to(device), labels.to(device)\n",
    "#         ancillary_optimizer.zero_grad()\n",
    "#         outputs = ancillary_model(ancillary_data)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         ancillary_optimizer.step()\n",
    "#         running_loss += loss.item()\n",
    "\n",
    "#     train_loss = running_loss / len(train_ancillary_loader)\n",
    "#     print(f'Epoch {epoch + 1}/{num_epochs}, Ancillary Model Loss: {train_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved successfully.\n"
     ]
    }
   ],
   "source": [
    "torch.save(image_model.state_dict(), 'image_model.pth')\n",
    "torch.save(ancillary_model.state_dict(), 'ancillary_model.pth')\n",
    "\n",
    "print(\"Models saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction and submission for image model\n",
    "image_model.eval()\n",
    "image_predictions = []\n",
    "image_ids = []\n",
    "with torch.no_grad():\n",
    "    for images, ids in test_image_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = image_model(images)\n",
    "        image_predictions.extend(outputs.cpu().numpy())\n",
    "        image_ids.extend([int(id) for id in ids])\n",
    "\n",
    "# # Prediction and submission for ancillary model\n",
    "# ancillary_model.eval()\n",
    "# ancillary_predictions = []\n",
    "# ancillary_ids = []\n",
    "# with torch.no_grad():\n",
    "#     for ancillary_data, ids in test_ancillary_loader:\n",
    "#         ancillary_data = ancillary_data.to(device)\n",
    "#         outputs = ancillary_model(ancillary_data)\n",
    "#         ancillary_predictions.extend(outputs.cpu().numpy())\n",
    "#         ancillary_ids.extend([int(id) for id in ids])\n",
    "\n",
    "# Prepare the submission files\n",
    "image_submission = pd.DataFrame(image_predictions, columns=['X4', 'X11', 'X18', 'X26', 'X50', 'X3112'])\n",
    "image_submission['id'] = image_ids\n",
    "image_submission = image_submission[['id', 'X4', 'X11', 'X18', 'X26', 'X50', 'X3112']]\n",
    "image_submission.to_csv('20941537_ye_image.csv', index=False)\n",
    "\n",
    "# ancillary_submission = pd.DataFrame(ancillary_predictions, columns=['X4', 'X11', 'X18', 'X26', 'X50', 'X3112'])\n",
    "# ancillary_submission['id'] = ancillary_ids\n",
    "# ancillary_submission = ancillary_submission[['id', 'X4', 'X11', 'X18', 'X26', 'X50', 'X3112']]\n",
    "# ancillary_submission.to_csv('20941537_ye_ancillary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
